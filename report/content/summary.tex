\pagebreak
\section{Tổng kết}

Gaussian Process (GP) được định nghĩa là một phân phối trên không gian các hàm số, trong đó việc lựa chọn hàm nhân (kernel) đóng vai trò quyết định đến độ trơn và hình dáng của các hàm được mô hình hóa. Về mặt toán học, GP dựa trên nền tảng của phân phối chuẩn đa biến, tận dụng các tính chất của phân phối biên và phân phối có điều kiện để thực hiện suy diễn.

Khi có một tập dữ liệu huấn luyện cho trước, mô hình cho phép tính toán kỳ vọng và độ lệch chuẩn để đưa ra dự đoán về hàm mục tiêu tại các điểm dữ liệu mới. Bên cạnh đó, GP có khả năng mở rộng linh hoạt để kết hợp thông tin đạo hàm nhằm cải thiện độ chính xác, cũng như tích hợp ước lượng nhiễu để xử lý dữ liệu thực tế một cách hiệu quả. Cuối cùng, các tham số của mô hình thường được ước lượng bằng phương pháp Ước lượng hợp lý cực đại (MLE) thông qua việc tối đa hóa hàm log likelihood.

Ta cũng đã trình bày lại phần bài tập để củng cố kiến thức về Gaussian Process, bao gồm các khía cạnh như lợi thế của GP so với mô hình hồi quy, độ phức tạp tính toán, vai trò của thông tin đạo hàm, và các phương pháp xử lý ngoại lai trong dữ liệu.

Cuối cùng, ta đã tìm hiểu một số hướng nghiên cứu gần đây trong lĩnh vực Gaussian Process. Những hướng đi này bao gồm việc cải thiện tính bền vững, tích hợp cấu trúc hình học và tô pô, cũng như khả năng kết hợp với các mô hình Generative AI hiện đại.